{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Torch Practice </h1>\n",
    "Where I play around with torch tutorials as well as test some implementation ideas\n",
    "<br> Note to self: Remember to read the API! <a href=\"https://pytorch.org/docs/stable/index.html\"> Link </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> April 20 2020: PyTorch Beginner Tutorial </h1>\n",
    "Just following the beginner tutorial  from <a href=\"https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\"> here </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Tensors </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.6040e+16, 9.0664e-43, 7.6040e+16],\n",
      "        [9.0664e-43, 7.6040e+16, 9.0664e-43],\n",
      "        [7.6040e+16, 9.0664e-43, 7.6040e+16],\n",
      "        [9.0664e-43, 7.6040e+16, 9.0664e-43],\n",
      "        [7.6040e+16, 9.0664e-43, 7.6040e+16]])\n"
     ]
    }
   ],
   "source": [
    "# construct a 5x3 matrix, uninitialized:\n",
    "x = torch.empty(5, 3)\n",
    "print(x) # whatever values are inside this \"empty\" matrix is just whatever values were in the allocated memory at the time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1465, 0.7502, 0.8895],\n",
      "        [0.5840, 0.1279, 0.9449],\n",
      "        [0.6140, 0.4411, 0.1912],\n",
      "        [0.9267, 0.1619, 0.3431],\n",
      "        [0.7339, 0.7059, 0.2059]])\n"
     ]
    }
   ],
   "source": [
    "# construct a randomly initialized matrix:\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# construct a matrix filled with zeros and of dtype long:\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# construct a tensor directly from data:\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.1752,  0.6100, -1.5148],\n",
      "        [ 0.1438,  2.2077,  1.2403],\n",
      "        [-0.7760,  1.8198,  0.4396],\n",
      "        [-1.0487,  0.0838, -1.0404],\n",
      "        [-0.4941,  0.1068, -1.2928]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# create a tensor based on an existing tensor. these methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user\n",
    "x = x.new_ones(5, 3, dtype=torch.double) # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=float) # override dtype!\n",
    "print(x) # result has the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# get its size \n",
    "print(x.size()) # torch,Size is a tuple, so it supports all tuple operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Operations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9651,  1.1894, -0.9744],\n",
      "        [ 0.4168,  3.1826,  1.5720],\n",
      "        [ 0.2210,  2.1405,  0.7205],\n",
      "        [-0.9441,  0.6162, -0.7964],\n",
      "        [-0.0211,  0.2507, -0.5799]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Addition with multiple syntaxes\n",
    "# First syntax\n",
    "y = torch.rand(5, 3)\n",
    "\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9651,  1.1894, -0.9744],\n",
      "        [ 0.4168,  3.1826,  1.5720],\n",
      "        [ 0.2210,  2.1405,  0.7205],\n",
      "        [-0.9441,  0.6162, -0.7964],\n",
      "        [-0.0211,  0.2507, -0.5799]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Second syntax\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9651,  1.1894, -0.9744],\n",
      "        [ 0.4168,  3.1826,  1.5720],\n",
      "        [ 0.2210,  2.1405,  0.7205],\n",
      "        [-0.9441,  0.6162, -0.7964],\n",
      "        [-0.0211,  0.2507, -0.5799]])\n"
     ]
    }
   ],
   "source": [
    "# Providing an output tensor as an argument \n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9651,  1.1894, -0.9744],\n",
      "        [ 0.4168,  3.1826,  1.5720],\n",
      "        [ 0.2210,  2.1405,  0.7205],\n",
      "        [-0.9441,  0.6162, -0.7964],\n",
      "        [-0.0211,  0.2507, -0.5799]])\n"
     ]
    }
   ],
   "source": [
    "# In-place addition\n",
    "y.add_(x)\n",
    "print(y)\n",
    "\n",
    "#any operation that mutates a tensor in-place is post-fixed with an _."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1752,  0.6100, -1.5148],\n",
      "        [ 0.1438,  2.2077,  1.2403],\n",
      "        [-0.7760,  1.8198,  0.4396],\n",
      "        [-1.0487,  0.0838, -1.0404],\n",
      "        [-0.4941,  0.1068, -1.2928]], dtype=torch.float64)\n",
      "tensor([0.6100, 2.2077, 1.8198, 0.0838, 0.1068], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# you can use standard NumPy-like indexing\n",
    "print(x)\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1647, -0.2865, -2.3422, -0.4476],\n",
      "        [ 0.5537, -1.4467, -0.3825,  0.9929],\n",
      "        [-0.6269,  0.6901,  0.7499, -0.3030],\n",
      "        [-0.9951, -0.5215, -0.1950, -1.0005]])\n",
      "tensor([ 0.1647, -0.2865, -2.3422, -0.4476,  0.5537, -1.4467, -0.3825,  0.9929,\n",
      "        -0.6269,  0.6901,  0.7499, -0.3030, -0.9951, -0.5215, -0.1950, -1.0005])\n",
      "tensor([[ 0.1647, -0.2865, -2.3422, -0.4476,  0.5537, -1.4467, -0.3825,  0.9929],\n",
      "        [-0.6269,  0.6901,  0.7499, -0.3030, -0.9951, -0.5215, -0.1950, -1.0005]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Resizing: If you want to resize/reshape tensor, you can use torch.view\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # -1 inferred from other dimensions\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.6952])\n",
      "-2.695227861404419\n"
     ]
    }
   ],
   "source": [
    "# if you have a one element tensor, use .item() to get the value as a Python number \n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read later: </b> <a href=\"https://pytorch.org/docs/stable/torch.html\"> PyTorch Torch Tensor Operations API </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> NumPy Bridge </h1>\n",
    "Converting a Torch Tensory to a NumPy array and vice versa <br>\n",
    "Note: The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Converting a Torch Tensor to a NumPy Array\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy() # turns the tensor a into a numpy array\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# notice how adding something to one of them will affect the other\n",
    "a.add_(1) # in place addition\n",
    "print(a)\n",
    "print(b)\n",
    "# print(b.add_(1)) <-- Error! b is a numpy array object, NOT a Tensor object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# See how changing the np array changed the Tensor Tensor automatically\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # turn the numpy array into a tensor \n",
    "np.add(a, 1, out=a) # numpy operation on the numpy array \n",
    "print(a)\n",
    "print(b) # both b's and a's values will be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CUDA Tensors </h1>\n",
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6952], device='cuda:0')\n",
      "tensor([-1.6952], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Tensors can be moved onto any device using the .to method:\n",
    "if torch.cuda.is_available(): # check if CUDA is available\n",
    "    device = torch.device(\"cuda\") # torch.device(device) can either be \"cpu\" or \"cuda\"\n",
    "    y = torch.ones_like(x, device=device) # directly create a tensor on GPU\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> AutoGrad: Automatic Differentiation </h1>\n",
    "The autograd package provides automatic differentiation for all operations on Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create a tensor and set requires_grad=True to track computation with it\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# do a tensor operation\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002875D0B0988>\n"
     ]
    }
   ],
   "source": [
    "# y was created as a result of an operation, so it has a grad_fn:\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# do more operations on y \n",
    "z = y * y * 3 \n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000002875CA647C8>\n"
     ]
    }
   ],
   "source": [
    "# .requires_grad_(...) changes an existing Tensor's require_grad flag in_place \n",
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Gradients </h1>\n",
    "Backprop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because out contains a single scalar, out.backward() is equivalent to out.backward(torch.tensor(1.))\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# print gradients d(out)/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  312.1145,  -350.2947, -1261.6964], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# let's take a look at an example of vector-Jacobian product: \n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "# now in this case y is no longer as scalar. torch.autograd could not compute the full jacobian directly, but if we just want the \n",
    "# vector-Jacobian product, simply pass the vector to backward as argument \n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# stop autograd from trackign history \n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# or by using .detach()\n",
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read later: </b> <a href=\"https://pytorch.org/docs/stable/autograd.html#function\"> PyTorch Autograd API </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Neural Networks </h1>\n",
    "Practice with using the torch.nn package with a basic feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self): # Constructor\n",
    "        super(Net, self).__init__() # super class constructor \n",
    "        \n",
    "        # 2 convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # affine operation: y = wx + b ( i think these are the actual hidden layers?)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120) # 6 * 6 image dimension \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # if the size is a square you can only specify a single number \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# the learnable parameters of a model are returned by net.parameters()\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0499,  0.1086, -0.1667,  ...,  0.4023, -0.5976, -1.1946],\n",
      "          [ 0.0148, -0.9079,  2.4513,  ..., -0.4476,  0.4506, -1.5137],\n",
      "          [ 0.2165, -0.1253,  0.0335,  ..., -0.3445,  1.4564, -1.1005],\n",
      "          ...,\n",
      "          [ 2.2433,  1.1902,  0.6741,  ...,  1.5873, -0.1161,  0.9130],\n",
      "          [-0.5422, -2.4781, -1.1004,  ...,  1.4735, -0.2849, -0.2638],\n",
      "          [-0.2167,  0.2619, -1.4728,  ...,  0.5453,  1.4421,  0.0563]]]])\n",
      "tensor([[-0.1005, -0.0357, -0.0490, -0.0313, -0.0556,  0.0207, -0.0768,  0.0381,\n",
      "         -0.0492,  0.0824]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# create a random 32 input and pass it into our net for evaluation \n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "print(input)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero the gradient buffers of all parameters and backprops with random gradients\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "# Note: torch.nn only supports mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loss Function </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9455, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10) # a dummy target\n",
    "target = target.view(1, -1) # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x000002875D052A08>\n",
      "<AddmmBackward object at 0x000002875D0401C8>\n",
      "<AccumulateGrad object at 0x000002875D052A08>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0]) # Linear \n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0015,  0.0167, -0.0229,  0.0053,  0.0159, -0.0050])\n"
     ]
    }
   ],
   "source": [
    "# to backpropagate the error all we have to do is to loss.backward()\n",
    "net.zero_grad() # zeroes the gradient buffers of all parameters\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read later: </b> <a href=\"https://pytorch.org/docs/stable/nn.html\"> PyTorch NN API </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Update the Weights </h1>\n",
    "<code> weight = weight - learning_rate * gradient </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use various update methods, such as this example\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad() # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Training a Classifier </h1>\n",
    "<ol>\n",
    "    <li> Load and normalize the CIFAR10 training and test datasets using <code> torchvision </code> </li>\n",
    "    <li> Define a CNN </li>\n",
    "    <li> Define a loss function </li>\n",
    "    <li> Train the network on the training data </li>\n",
    "    <li> Test the network on the test data </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loading and Normalizing CIFAR10 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea211896555f4140b995dd4a502ef7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transforming the dataset images from PILImages of range [0, 1] to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bird   car  deer  deer\n"
     ]
    }
   ],
   "source": [
    "# Show some of the training images for fun\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels \n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define a CNN </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
